import gc
import torch
import re
from typing import List, Tuple, Dict, Set
from concurrent.futures import ThreadPoolExecutor
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import MatchValue, MatchAny, Filter, FieldCondition
from sklearn.metrics.pairwise import cosine_similarity


# âœ… Qdrant ì„¤ì •
qdrant_client = QdrantClient(host="localhost", port=6333)
collection_name = "docs_test_all"

# âœ… SentenceTransformer (KURE_v1)
model = SentenceTransformer("/home/hmo/Embedding_Models/KURE_v1")


def encode_and_clear(texts, **kwargs):
    vectors = model.encode(texts, **kwargs)
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()
    return vectors


# âœ… ê³µí†µ ì ìˆ˜ ë³´ì • í•¨ìˆ˜ (ë‚ ì§œ ì—¬ë¶€ ë¬´ê´€)
def apply_keyword_bonus(results, text_keywords, top_k):
    """ê²€ìƒ‰ ê²°ê³¼ì— í‚¤ì›Œë“œ êµì§‘í•© ê¸°ë°˜ ì ìˆ˜ ë³´ë„ˆìŠ¤ ì ìš©"""
    reranked = []
    for hit in results:
        payload = hit.payload
        score = float(hit.score)
        doc_keywords = payload.get("keywords", [])

        matched_keywords = []
        for kw in text_keywords:
            if kw in (payload.get("sFileName") or "") or kw in doc_keywords:
                matched_keywords.append(kw)

        # âœ… êµì§‘í•© ë³´ë„ˆìŠ¤ (0.05, 0.04, 0.03, ...)
        for i, _ in enumerate(matched_keywords):
            score += max(0.05 - i * 0.01, 0.01)

        if matched_keywords:
            print(f"\nğŸ“„ {payload.get('sFileName', '')}")
            print(f"   ğŸ”¹ ë¬¸ì„œ keywords: {doc_keywords}")
            print(f"   ğŸ”¹ ë§¤ì¹­: {matched_keywords} â†’ ìµœì¢… score={round(score,5)}")

        reranked.append({
            "id": hit.id,
            "ë¬¸ì„œID": payload.get("doc_id", ""),
            "íŒŒì¼ëª…": payload.get("sFileName", ""),
            "ë‚ ì§œ": f"{payload.get('year', '----')}-{payload.get('month', '--')}-{payload.get('day', '--')}",
            "ê²½ë¡œ": payload.get("sFilePath", ""),
            "ë³´ì•ˆë“±ê¸‰": payload.get("sGrade", ""),
            "score": round(score, 5),
        })

    reranked.sort(key=lambda x: x["score"], reverse=True)
    return reranked[:top_k]


# âœ… ë‹¨ì¼ í‚¤ì›Œë“œ ê²€ìƒ‰
def keyword_search_single(keyword: str, top_k: int = 30) -> Tuple[Set, Dict, str]:
    keyword_type = "none"
    query_filter = None

    if re.fullmatch(r"\d{4}", keyword):  # ì—°ë„
        keyword_type = "year"
        query_filter = Filter(must=[FieldCondition(key="year", match=MatchValue(value=int(keyword)))])
    elif keyword.isdigit() and 1 <= int(keyword) <= 12:  # ì›”
        keyword_type = "month"
        query_filter = Filter(must=[FieldCondition(key="month", match=MatchValue(value=int(keyword)))])
    elif keyword.isdigit() and 1 <= int(keyword) <= 31:  # ì¼
        keyword_type = "day"
        query_filter = Filter(must=[FieldCondition(key="day", match=MatchValue(value=int(keyword)))])
    else:  # í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ
        keyword_type = "text"
        query_filter = Filter(should=[
            FieldCondition(key="sFileName", match=MatchValue(value=keyword)),
            FieldCondition(key="keywords", match=MatchAny(any=[keyword])),
        ])

    result = qdrant_client.query_points(
        collection_name=collection_name,
        query_filter=query_filter,
        limit=top_k,
        with_payload=True,
        with_vectors=True,
    )

    ids = {p.id for p in result.points}
    payloads = {p.id: {"payload": p.payload, "vector": p.vector} for p in result.points}
    return ids, payloads, keyword_type


# âœ… ë³‘ë ¬ í‚¤ì›Œë“œ ê²€ìƒ‰
def search_qdrant_metadata_parallel(keywords: List[str], top_k_per_keyword: int = 50) -> Tuple[Dict, Dict, Dict]:
    all_payloads = {}
    keyword_results = {}
    keyword_types = {}

    if not keywords:
        return {}, {}, {}

    with ThreadPoolExecutor(max_workers=max(1, len(keywords))) as executor:
        futures = {executor.submit(keyword_search_single, kw, top_k_per_keyword): kw for kw in keywords}
        for future in futures:
            ids, payloads, kw_type = future.result()
            kw = futures[future]
            keyword_results[kw] = ids
            keyword_types[kw] = kw_type
            all_payloads.update(payloads)

    return keyword_results, all_payloads, keyword_types


# âœ… ë‚ ì§œ + í‚¤ì›Œë“œ ê²°í•© ê²€ìƒ‰
def keyword_then_semantic_rerank(question: str, keywords: List[str], top_k: int = 5):
    print("\n" + "=" * 80)
    print(f"ğŸ§© [keyword_then_semantic_rerank] ê²€ìƒ‰ ìš”ì²­ ì‹œì‘")
    print(f"ğŸ“¥ ì§ˆë¬¸: {question}")
    print(f"ğŸ”‘ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸: {keywords}")
    print("=" * 80)

    keyword_results, all_payloads, keyword_types = search_qdrant_metadata_parallel(keywords, top_k_per_keyword=200)
    date_keywords = [kw for kw, t in keyword_types.items() if t in ("year", "month", "day")]
    text_keywords = [kw for kw, t in keyword_types.items() if t == "text"]

    print(f"ğŸ“… ë‚ ì§œ í‚¤ì›Œë“œ: {date_keywords if date_keywords else 'ì—†ìŒ'}")
    print(f"ğŸ’¬ í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ: {text_keywords if text_keywords else 'ì—†ìŒ'}")

    # ë‚ ì§œê°€ í¬í•¨ëœ ê²½ìš°
    if date_keywords:
        print("\nâš¡ [1ë‹¨ê³„] ë‚ ì§œ + í‚¤ì›Œë“œ ê²°í•© â†’ Qdrant ê²€ìƒ‰ ì‹¤í–‰")
        query_vector = encode_and_clear([question])[0]

        must_conditions = []
        for kw in date_keywords:
            kw_type = keyword_types[kw]
            if kw_type == "year":
                must_conditions.append(FieldCondition(key="year", match=MatchValue(value=int(kw))))
            elif kw_type == "month":
                must_conditions.append(FieldCondition(key="month", match=MatchValue(value=int(kw))))
            elif kw_type == "day":
                must_conditions.append(FieldCondition(key="day", match=MatchValue(value=int(kw))))

        if text_keywords:
            should_conditions = []
            for kw in text_keywords:
                should_conditions.extend([
                    FieldCondition(key="sFileName", match=MatchValue(value=kw)),
                    FieldCondition(key="keywords", match=MatchAny(any=[kw])),
                    FieldCondition(key="keywords", match={"text": kw}),
                ])
            must_conditions.append(Filter(should=should_conditions))

        filter_query = Filter(must=must_conditions)
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=filter_query,
            limit=top_k * 10,
            with_payload=True
        )

        # âœ… ê²°ê³¼ ì—†ì„ ê²½ìš° â†’ ì˜ë¯¸ê²€ìƒ‰ fallback
        if not results:
            print("âš ï¸ [1ë‹¨ê³„] ê²€ìƒ‰ ê²°ê³¼ 0ê±´ â†’ ì˜ë¯¸ê²€ìƒ‰ fallback ì‹¤í–‰")
            return semantic_vector_search(question, top_k)

       # print(f"ğŸ“Š Qdrant ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´\n")
        return apply_keyword_bonus(results, text_keywords, top_k)

    # í‚¤ì›Œë“œë§Œ ìˆì„ ê²½ìš°
    elif text_keywords:
        print("\nğŸ”¤ [2ë‹¨ê³„] í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤í–‰")
        query_vector = encode_and_clear([question])[0]
        should_conditions = []
        for kw in text_keywords:
            should_conditions.extend([
                FieldCondition(key="sFileName", match=MatchValue(value=kw)),
                FieldCondition(key="keywords", match=MatchAny(any=[kw])),
                FieldCondition(key="keywords", match={"text": kw}),
            ])
        filter_query = Filter(should=should_conditions)
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=filter_query,
            limit=top_k * 10,
            with_payload=True
        )

        # âœ… ê²°ê³¼ ì—†ì„ ê²½ìš° â†’ ì˜ë¯¸ê²€ìƒ‰ fallback
        if not results:
            print("âš ï¸ [2ë‹¨ê³„] ê²€ìƒ‰ ê²°ê³¼ 0ê±´ â†’ ì˜ë¯¸ê²€ìƒ‰ fallback ì‹¤í–‰")
            return semantic_vector_search(question, top_k)

        #print(f"ğŸ“Š Qdrant ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´\n")
        return apply_keyword_bonus(results, text_keywords, top_k)

    # ì•„ë¬´ê²ƒë„ ì—†ì„ ê²½ìš° â†’ ì˜ë¯¸ê²€ìƒ‰ fallback
    else:
        print("\nâš ï¸ [3ë‹¨ê³„] í•„í„° ì—†ìŒ â†’ ì „ì²´ ì˜ë¯¸ê²€ìƒ‰ fallback")
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=encode_and_clear([question])[0],
            limit=top_k * 10,
            with_payload=True
        )
        return apply_keyword_bonus(results, keywords, top_k)


# âœ… ì˜ë¯¸ê²€ìƒ‰ fallback (ë‹¨ìˆœ ë²¡í„°ê²€ìƒ‰)
def semantic_vector_search(question: str, top_k: int = 30):
    query_vector = encode_and_clear([question])[0]
    results = qdrant_client.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=top_k,
        with_payload=True
    )
    return [
        {
            "id": hit.id,
            "ë¬¸ì„œID": hit.payload.get("doc_id", ""),
            "í˜ì´ì§€": hit.payload.get("nPage", ""),
            "íŒŒì¼ëª…": hit.payload.get("sFileName", ""),
            "ë‚ ì§œ": f"{hit.payload.get('year', '----')}-{hit.payload.get('month', '--')}-{hit.payload.get('day', '--')}",
            "ê²½ë¡œ": hit.payload.get("sFilePath", ""),
            "ë³´ì•ˆë“±ê¸‰": hit.payload.get("sGrade", ""),
            "score": round(hit.score, 5),
        }
        for hit in results
    ]
