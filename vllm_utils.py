import requests
import re

# âœ… vLLM API ì„œë²„ (Qwen32B ê¸°ë°˜)
VLLM_API_URL = "http://localhost:8000/v1/completions"  # â† ì‹¤ì œ í¬íŠ¸ í™•ì¸ í•„ìš”
MODEL_ID = "/model"  # ë„ì»¤ ë‚´ Qwen3-32B ê²½ë¡œ (vLLM ê¸°ë³¸ê°’)

# âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (think ì°¨ë‹¨ + í•œêµ­ì–´ ì‘ë‹µ ê³ ì •)
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
- ëª¨ë“  ë‹µë³€ì€ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- í•„ìš”í•  ë•Œ ì˜ì–´ ê¸°ìˆ  ìš©ì–´(GPU, Docker, API ë“±)ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ë„ ë©ë‹ˆë‹¤.
- <think>ë‚˜ reasoning ë“±ì˜ ë‚´ë¶€ ì‚¬ê³  ê³¼ì •ì„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
- ê·¸ëŸ¬ë‚˜ ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‹µì´ë‚˜ ë¬¸ì¥, ëª©ë¡, ìš”ì•½ì€ ë°˜ë“œì‹œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
"""


# âœ… 1ï¸âƒ£ vLLM API í˜¸ì¶œ í•¨ìˆ˜
def call_vllm(prompt, max_tokens=256, stop=None):
    try:
        # ğŸ”¹ ìš”ì²­ JSON êµ¬ì„±
        payload = {
            "model": MODEL_ID,
            "prompt": prompt.strip(),
            "max_tokens": max_tokens,
            "temperature": 0.4,
        }
        if stop:
            payload["stop"] = stop

        response = requests.post(
            VLLM_API_URL,
            headers={"Content-Type": "application/json"},
            json=payload,
            timeout=60
        )

        response.raise_for_status()
        result = response.json()

        # ğŸ”¹ LLM ì‘ë‹µ ì¶”ì¶œ
        choices = result.get("choices", [])
        if choices and "text" in choices[0]:
            text = choices[0].get("text", "").strip()
            # âœ… think / system / reasoning í•„í„°ë§
            text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)
            text = re.sub(r"(?i)(reasoning|analysis|step[- ]?by[- ]?step).*", "", text)
            return text.strip()

        return "[âš ï¸ LLM ì‘ë‹µì— í…ìŠ¤íŠ¸ ì—†ìŒ]"

    except requests.RequestException as e:
        print(f"[âŒ vLLM í˜¸ì¶œ ì‹¤íŒ¨]: {e}")
        return "[âŒ LLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨]"

# âœ… 2ï¸âƒ£ ë¬¸ì„œ ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ìƒì„± í•¨ìˆ˜
def call_vllm_generate_search_condition(user_question):
    prompt = f"""
ë„ˆëŠ” í•œêµ­ì–´ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ í‚¤ì›Œë“œ ìƒì„± ì „ë¬¸ê°€ì•¼.
ë‹¤ìŒ ê·œì¹™ì„ ì² ì €íˆ ì§€ì¼œì„œ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ëœ í•µì‹¬ ë‹¨ì–´ë§Œ ì¶œë ¥í•´.
ì„¤ëª…, ë¬¸ì¥, ë¶ˆë¦¿, <think> ê°™ì€ ë‚´ë¶€ ë¬¸ì¥ì€ ì ˆëŒ€ ì“°ë©´ ì•ˆ ë¼.

ê·œì¹™:
1. ì—°ë„ê°€ í¬í•¨ë˜ë©´ ë°˜ë“œì‹œ ìˆ«ì 4ìë¦¬ë¡œ í¬í•¨ (ì˜ˆ: "23ë…„ë„" â†’ "2023").
2. ì›”, ì¼ ë‹¨ìœ„ëŠ” ë°˜ë“œì‹œ ìˆ«ìë§Œ í¬í•¨ (ì˜ˆ: "1ì›”" â†’ "1", "12ì›”" â†’ "12", "15ì¼" â†’ "15").
3. **ë¶™ì–´ ìˆëŠ” ë³µí•© ëª…ì‚¬(ì˜ˆ: "ì„¤ë¹„ê¸°ìˆ ê·¸ë£¹", "í’ˆì§ˆë³´ì¦íŒ€", "ê³µì •ê´€ë¦¬íŒŒíŠ¸")ëŠ” ì ˆëŒ€ ë¶„ë¦¬í•˜ì§€ ë§ ê²ƒ.**
4. ë„ì–´ì“°ê¸° ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ìë¥´ì§€ ë§ê³ , ì‹¤ì œ ì˜ë¯¸ ë‹¨ìœ„(ëª…ì‚¬ ë‹¨ì–´)ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€.
5. ë‹¨ì–´ ì‚¬ì´ì—ëŠ” ì‰¼í‘œ(,)ë§Œ ì‚¬ìš©í•˜ê³ , ê³µë°±ì´ë‚˜ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ.
6. íŠ¹ìˆ˜ë¬¸ì, ë”°ì˜´í‘œ, ë§ˆì¹¨í‘œ, ê°œí–‰, HTML íƒœê·¸ëŠ” ê¸ˆì§€.
7. "í‚¤ì›Œë“œ:"ë‚˜ ë¶ˆí•„ìš”í•œ ì ‘ë‘ì–´/ì ‘ë¯¸ì–´ ì—†ì´ í‚¤ì›Œë“œë§Œ ì¶œë ¥.

ì˜ˆì‹œ:
- ì…ë ¥: "2024ë…„ 1ì›” ì„¤ë¹„ê¸°ìˆ ê·¸ë£¹ í™œë™ ì¼ì§€"
  ì¶œë ¥: 2024,1,ì„¤ë¹„ê¸°ìˆ ê·¸ë£¹,í™œë™,ì¼ì§€
- ì…ë ¥: "2023ë…„ 3ì›” 15ì¼ ê³ ì¥ ì´ë ¥"
  ì¶œë ¥: 2023,3,15,ê³ ì¥,ì´ë ¥
- ì…ë ¥: "ì„¤ë¹„ê³ ì¥ ì´ë ¥"
  ì¶œë ¥: ì„¤ë¹„ê³ ì¥,ì´ë ¥

ì§ˆë¬¸: {user_question}

í‚¤ì›Œë“œ:
"""
    return call_vllm(prompt, max_tokens=64, stop=["\n"])


# âœ… 3ï¸âƒ£ í‚¤ì›Œë“œ í›„ì²˜ë¦¬
def clean_llm_keywords(raw_text: str) -> list:
    first_line = raw_text.strip().split("\n")[0]
    cleaned = re.sub(r"<[^>]+>", "", first_line)
    cleaned = re.sub(r"(?i)(í‚¤ì›Œë“œ|ì§ˆë¬¸)\s*:.*", "", cleaned)
    cleaned = re.sub(r"[\r\n\t]", " ", cleaned)
    cleaned = re.sub(r"\s+", " ", cleaned).strip()

    # âœ… thinkë‚˜ ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê±°
    if "LLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨" in cleaned or "think" in cleaned.lower():
        return []
    return [kw.strip() for kw in cleaned.split(",") if kw.strip()]

# âœ… 4ï¸âƒ£ ê¸°ì‚¬ ìš”ì•½ í•¨ìˆ˜
def call_vllm_summarize_article(article_text, user_question=None):
    cleaned_text = clean_article_text(article_text)

    # âœ… 1ï¸âƒ£ ë‚´ìš© ìœ íš¨ì„± ê²€ì‚¬ (íŒŒì¼ëª…/í™•ì¥ì/ë„ˆë¬´ ì§§ì€ ë³¸ë¬¸ ë“±)
    if not cleaned_text.strip():
        return "ë‚´ìš©ì—†ìŒ"
    if re.match(r"^[\w\W]*\.(pptx|xlsx|docx|pdf)[\w\W]*$", cleaned_text):
        return "ë‚´ìš©ì—†ìŒ"
    if len(cleaned_text) < 30:  # ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ì€ ê²½ìš° (ì˜ˆ: íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ ë“±)
        return "ë‚´ìš©ì—†ìŒ"

    # âœ… 2ï¸âƒ£ ìš”ì•½ í”„ë¡¬í”„íŠ¸
    prompt = f"""
ë‹¤ìŒì€ ê¸°ìˆ  ë¬¸ì„œ ë˜ëŠ” ê¸°ë¡í‘œì…ë‹ˆë‹¤.
í•µì‹¬ ë‚´ìš©ì„ 3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.

ì¡°ê±´:
- "ìš”ì•½"ì´ë¼ëŠ” ë‹¨ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ë™ì¼í•œ ì‚¬ì‹¤ì´ë‚˜ ìˆ«ìë¥¼ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”.
- ë³¸ë¬¸ì´ ë¹„ì–´ ìˆê±°ë‚˜ ì˜ë¯¸ê°€ ì—†ìœ¼ë©´ "ë‚´ìš©ì—†ìŒ"ì´ë¼ê³ ë§Œ ëŒ€ë‹µí•˜ì„¸ìš”.

[ë³¸ë¬¸]
{cleaned_text}
"""
    raw_summary = call_vllm(prompt, max_tokens=512)
    return clean_sentences_preserve_meaning(raw_summary)


# âœ… 5ï¸âƒ£ ë¬¸ì¥ ì •ì œ
def clean_sentences_preserve_meaning(text: str) -> str:
    text = re.sub(r"<[^>]+>", "", text)
    text = re.sub(r"[\r\n\t]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# âœ… 6ï¸âƒ£ ë³¸ë¬¸ ì •ì œ
def clean_article_text(text: str) -> str:
    text = text.replace("\n", " ").replace("\r", " ")
    text = text.replace("â€œ", '"').replace("â€", '"')
    text = text.replace("â€˜", "'").replace("â€™", "'")
    text = re.sub(r"\([^)]{0,30}\)", "", text)
    text = re.sub(r"[â€¢â˜…â˜†â–¶â–²â–¼â†’â€»]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text
